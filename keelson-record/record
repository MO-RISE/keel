#!/usr/bin/env python3

import json
import time
import atexit
import logging
import pathlib
import warnings
import argparse
from queue import Queue
from threading import Thread
from typing import Dict, Tuple
from contextlib import contextmanager

import zenoh
from mcap.writer import Writer
from mcap.well_known import SchemaEncoding, MessageEncoding
from google.protobuf.message import DecodeError


import brefv

logger = logging.getLogger("keelson-record")

BREFV_TO_MCAP_MESSAGE_ENCODING_MAP = {"json": "json", "protobuf": "protobuf"}


@contextmanager
def ignore(*exceptions):
    try:
        yield
    except exceptions:
        logger.exception("Something went wrong in the listener!")


def run(session: zenoh.Session, args: argparse.Namespace):
    queue = Queue()

    with args.output.open("wb") as fh:
        # Initiate writer
        writer = Writer(fh)
        writer.start()

        schemas: Dict[str, Tuple[MessageEncoding, int]] = {}
        channels: Dict[str, int] = {}

        def _recorder():
            while item := queue.get():
                logger.debug("Writing item to file: %s", item)
                try:
                    channel_id, received_at, enclosed_at, payload = item
                    writer.add_message(
                        channel_id=channel_id,
                        log_time=received_at,
                        publish_time=enclosed_at,
                        data=payload,
                    )
                except Exception:
                    logger.exception("Could not write item: %s to file!", item)

        t = Thread(target=_recorder)
        t.daemon = True
        t.start()

        def _listener(sample: zenoh.Sample):
            with ignore(Exception):
                topic = str(sample.key_expr)
                logger.debug("Received sample on topic: %s", topic)

                # Uncover from brefv envelope
                try:
                    received_at, enclosed_at, payload = brefv.uncover(
                        sample.value.payload
                    )
                except DecodeError:
                    logger.exception(
                        "Topic %s did not contain a valid brefv.Envelope: %s",
                        topic,
                        sample.value.payload,
                    )
                    return

                # If this topic is known
                if topic in channels:
                    logger.debug(
                        "Topic %s is already known! Putting to queue...", topic
                    )
                    queue.put((channels[topic], received_at, enclosed_at, payload))
                    return

                try:
                    tag = brefv.get_tag_from_pub_sub_topic(topic)
                except ValueError:
                    logger.exception(
                        "Received topic did not match the expected format: %s", topic
                    )
                    return

                logger.info("Unseen topic %s, adding to file", topic)

                # IF we havent already got a schema for this tag
                if not tag in schemas:
                    logger.debug("Tag %s not seen before", tag)

                    match brefv.is_tag_well_known(tag):
                        case True:
                            logger.debug("Tag %s is well-known!", tag)
                            # Get info about the well-known tag
                            brefv_encoding = brefv.get_tag_encoding(tag)
                            brefv_description = brefv.get_tag_description(tag)

                            # Which encoding?
                            match brefv_encoding:
                                case "protobuf":
                                    logger.debug("...of protobuf encoding.")
                                    file_descriptor_set = brefv.get_protobuf_file_descriptor_set_from_type_name(
                                        brefv_description
                                    )
                                    schemas[tag] = (
                                        MessageEncoding.Protobuf,
                                        writer.register_schema(
                                            name=brefv_description,
                                            encoding=SchemaEncoding.Protobuf,
                                            data=file_descriptor_set.SerializeToString(),
                                        ),
                                    )

                                case "json":
                                    logger.debug("...of JSON encoding")
                                    schemas[tag] = (
                                        MessageEncoding.JSON,
                                        writer.register_schema(
                                            name=tag,
                                            encoding=SchemaEncoding.JSONSchema,
                                            data=brefv_description.encode(),
                                        ),
                                    )

                                case _:
                                    logger.error(
                                        "Brefv tag encoding: %s is not supported! Storing without schema.",
                                        brefv_encoding,
                                    )
                                    schemas[tag] = (
                                        "",
                                        writer.register_schema(
                                            name=tag,
                                            encoding=SchemaEncoding.SelfDescribing,
                                            data=b"",
                                        ),
                                    )

                        case False:
                            logger.info(
                                "Unknown tag, we make a guess on the encoding..."
                            )
                            try:
                                # We make a guess at JSON, since it is common for rapid prototyping
                                json.loads(payload)
                                schemas[tag] = (
                                    MessageEncoding.JSON,
                                    writer.register_schema(
                                        name=tag,
                                        encoding=SchemaEncoding.JSONSchema,
                                        data=b"",
                                    ),
                                )
                                logger.debug("...its JSON!")
                            except (json.JSONDecodeError, UnicodeDecodeError):
                                # Otherwise, we have no idea...
                                schemas[tag] = (
                                    "",
                                    writer.register_schema(
                                        name=tag,
                                        encoding=SchemaEncoding.SelfDescribing,
                                        data=b"",
                                    ),
                                )
                                logger.debug("...no luck, storing without schema.")

                # Now we have a schema_id, moving on to registering a channel
                message_encoding, schema_id = schemas[tag]

                logger.debug(
                    "Registering a channel (%s) with schema_id=%s and message_encoding=%s",
                    topic,
                    schema_id,
                    message_encoding,
                )

                channels[topic] = writer.register_channel(
                    topic=topic, message_encoding=message_encoding, schema_id=schema_id
                )

                # Finally, put the sample on the queue
                logger.debug("...and putting our new sample on the queue!")
                queue.put((channels[topic], received_at, enclosed_at, payload))

        # And start subscribing
        subscribers = [session.declare_subscriber(key, _listener) for key in args.key]

        while True:
            try:
                qsize = queue.qsize()
                logger.debug("Approximate queue size is: %s", qsize)

                if qsize > 100:
                    warnings.warn("Queue size is %s", qsize)
                elif qsize > 1000:
                    raise RuntimeError(
                        f"Recorder is not capable of keeping up with data flow. Current queue size is {qsize}. Exiting!"
                    )
                
                time.sleep(1.0)
            except KeyboardInterrupt:
                logger.info("Closing down on user request!")
                logger.debug("Undeclaring subscribers...")
                for sub in subscribers:
                    sub.undeclare()

                logger.debug("Waiting for all items in queue to be processed...")
                queue.join()

                logger.debug("Finishing output file...")
                writer.finish()

                logger.debug("Done! Good bye :)")
                break


def main():
    parser = argparse.ArgumentParser(
        prog="record",
        description="A pure python recorder for keelson",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument("--log-level", type=int, default=logging.INFO)

    parser.add_argument(
        "-k",
        "--key",
        type=str,
        action="append",
        required=True,
        help="Key expressions to subscribe to from the Zenoh session",
    )

    parser.add_argument(
        "-o",
        "--output",
        type=pathlib.Path,
        required=True,
        help="File path to write recording to",
    )

    ## Parse arguments and start doing our thing
    args = parser.parse_args()

    # Setup logger
    logging.basicConfig(
        format="%(asctime)s %(levelname)s %(name)s %(message)s", level=args.log_level
    )
    logging.captureWarnings(True)
    zenoh.init_logger()

    # Put together zenoh session configuration
    conf = zenoh.Config()
    conf.insert_json5(zenoh.config.MODE_KEY, json.dumps("peer"))

    ## Construct session
    logger.info("Opening Zenoh session...")
    session = zenoh.open(conf)

    def _on_exit():
        session.close()

    atexit.register(_on_exit)

    run(session, args)


if __name__ == "__main__":
    main()
